{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tasnet","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"_xuWGpScqQH8","colab_type":"text"},"source":["# TasNet Bakalarka\n","- install pytorch\n","- check that cuda exists\n","- update repository in Google Drive\n","  - load data from Google Drive - Use Collab modified code\n","  - save reconstruction back to Google Drive\n","- Import libs - torchvision, scipy, etc.\n","- train nn\n","- save graph and hyper parameters into file, to know the best NN configuration"]},{"cell_type":"markdown","metadata":{"id":"PfQ01bj7SN0z","colab_type":"text"},"source":["## TODO\n","- save this notebook to github repo after finished work\n","- load this notebook from github before continuing work\n","- udelat pro kazde nove trenovani slozku kam se ulozi loss soubor, separated audios, checkpointy, inference file, ..."]},{"cell_type":"markdown","metadata":{"id":"X8pnng8uOf3S","colab_type":"text"},"source":["## Prepare Google Drive with data"]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"60c8e9fe-cdc9-4050-e4b9-5e2af7072256","executionInfo":{"status":"ok","timestamp":1573569321541,"user_tz":-60,"elapsed":25203,"user":{"displayName":"narutokov","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAyJj_235BHAe-AhCcabJ67rI8ms6VvOAQiExuQ=s64","userId":"09699004457365288649"}},"id":"75e2X4bWZrRS","colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"s65oM83HZ7tw","colab_type":"text"},"source":["## Load Single file from github"]},{"cell_type":"code","metadata":{"id":"ixkljqm4fvQm","colab_type":"code","colab":{}},"source":["# Fetch a single <1MB file using the raw GitHub URL.\n","!curl --remote-name \\\n","     -H 'Accept: application/vnd.github.v3.raw' \\\n","     --location https://api.github.com/repos/valgrut/TasNet/colab/tasnet.ipynb"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b0mwmOVJc28W","colab_type":"text"},"source":["## Save notebooks to my repo on github"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"BW-ZErjaicZi","colab":{}},"source":["GIT_USERNAME = \"valgrut\"\n","GIT_TOKEN = \"XXX\"\n","GIT_REPOSITORY = \"TasNet\"\n","\n","PROJECT_PATH = r\"/gdrive/My Drive/FIT/\"\n","\n","!mkdir ./temp\n","!git clone \"https://{GIT_TOKEN}@github.com/{GIT_USERNAME}/{GIT_REPOSITORY}.git\" ./temp\n","#!rsync -aP --exclude=data/ \"{PROJECT_PATH}\"/* ./temp\n","\n","%cd ./temp\n","!git add .\n","!git commit -m '\"New Version of TasNet\"'\n","!git config --global user.email \"naruto987@seznam.cz\"\n","!git config --global user.name \"valgrut\"\n","!git push origin \"master\"\n","%cd ../\n","!rm -rf ./temp"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wKFxIQTBktqt","colab_type":"text"},"source":["## Save notebooks to tasnet repo on local\n","DOESNT WORK NOW\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2mP-KYneo9ta","outputId":"5f06e82e-7aa0-4998-fdca-84fdae5a2b3f","executionInfo":{"status":"error","timestamp":1573497375575,"user_tz":-60,"elapsed":2936,"user":{"displayName":"narutokov","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAyJj_235BHAe-AhCcabJ67rI8ms6VvOAQiExuQ=s64","userId":"09699004457365288649"}},"colab":{"base_uri":"https://localhost:8080/","height":556}},"source":["from google.colab import files\n","from google.colab import drive\n","import zipfile\n","import sys\n","drive.mount('/gdrive')\n","\n","!ls \"/gdrive/My Drive/Colab Notebooks/\"\n","\n","%cd \"/gdrive/My Drive/Colab Notebooks/\"\n","!ls\n","#files.download('/gdrive/My Drive/Colab Notebooks/tasnet.ipynb')\n","\n","\n","foldername = 'colabnotebooks'\n","zipfile.ZipFile('/gdrive/My Drive/'+foldername + '.zip', 'w', zipfile.ZIP_DEFLATED)\n","\n","#Downloading the data from the colab\n","\n","from google.colab import files\n","files.download('/gdrive/My Drive/test.zip')\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n","'Copy of 01.05-IPython-And-Shell-Commands.ipynb'\n","'Copy of colab-github-demo.ipynb'\n","'Copy of External data: Local Files, Drive, Sheets, and Cloud Storage'\n","'Copy of pytorch_feedforward_neural_network.ipynb'\n","'Copy of Welcome To Colaboratory'\n","'Copy of Welcome To Colaboratory (1)'\n"," DrivePytorchBasics.ipynb\n"," tasnet.ipynb\n","'Tensor basics - Shaping, viewing.ipynb'\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-5b15888b8c1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/gdrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ls \"/gdrive/My Drive/Colab Notebooks/\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd \"/gdrive/My Drive/Colab Notebooks/\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    436\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   result = _run_command(\n\u001b[0;32m--> 438\u001b[0;31m       shell.var_expand(cmd, depth=2), clear_streamed_output=False)\n\u001b[0m\u001b[1;32m    439\u001b[0m   \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_INTERRUPTED_SIGNALS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    193\u001b[0m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_pty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_monitor_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_stdin_widget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_display_stdin_widget\u001b[0;34m(delay_millis)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m   \u001b[0mhide_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'cell_remove_stdin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m   \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocking_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mhide_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_header\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   \u001b[0;31m# unique.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0mrequest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msend_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"j2bMCh9efEw8","colab_type":"text"},"source":["# Libs, params, classes definition"]},{"cell_type":"markdown","metadata":{"id":"BNU3SHR5Nlu1","colab_type":"text"},"source":["## Import libs\n"]},{"cell_type":"code","metadata":{"id":"5_0Q1MeKNYCK","colab_type":"code","colab":{}},"source":["import tkinter\n","from datetime import datetime\n","from scipy.io import wavfile as wav\n","import matplotlib.pyplot as plt\n","from torch.autograd import Variable\n","import torchvision.transforms as transforms\n","import IPython.display as ipd\n","import numpy as np\n","import torch\n","import torch.utils.data as data_utils\n","from torch._six import int_classes as _int_classes\n","import signal\n","import sys\n","from os import listdir\n","from os.path import isfile, join\n","import torch.optim as optim\n","import torch.nn as nn\n","import torch.nn.functional as fc"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9zIPLH3ZNhbg","colab_type":"text"},"source":["## Hyperparameters for NN"]},{"cell_type":"code","metadata":{"id":"UMZ1M3aQNgL2","colab_type":"code","colab":{}},"source":["### HYPERPARAMETERS ###\n","DEBUG = False\n","\n","BASE_DATA_PATH=r\"/gdrive/My Drive/FIT/\"\n","\n","MINIBATCH_SIZE  = 1       # TODO Problem s rozmerama pri hodnote > 1\n","R = 2 #number of repeats of ConvBlocks\n","X = 8 #num of ConvBlocks in one repeat\n","\n","optim_SGD       = False   # Adam / SGD\n","learning_rate   = 0.0001\n","opt_decay       = 0       # 0.0001\n","\n","bias_enabled    = False\n","padd            = 10       # 20 nebo 10??\n","nn_stride       = 20\n","\n","use_cuda        = True\n","epochs          = 3\n","audios_in_epoch = 20000 # kolik zpracovat nahravek v jedne epose\n","\n","audio_save_frequency = 5000\n","print_loss_frequency = 5000 # za kolik segmentu (minibatchu) vypisovat loss\n","print_valid_loss_frequency = 5000\n","#log_loss_frequency = 5000\n","create_checkpoint_frequency = 5000\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LfsnpnXuNrvt","colab_type":"text"},"source":["## ResBlock class"]},{"cell_type":"code","metadata":{"id":"-BUAJ6lzN1w2","colab_type":"code","colab":{}},"source":["class ResBlock(nn.Module):\n","    def __init__(self, in_channels, dilation):\n","        super(ResBlock, self).__init__()\n","        self.dilation = dilation\n","\n","        self.conv1 = nn.Conv1d(256, 512, kernel_size=1)\n","        self.D_conv = nn.Conv1d(512, 512, kernel_size=3, padding=self.dilation, groups=512, dilation=self.dilation)\n","        self.conv2 = nn.Conv1d(512, 256, kernel_size=1)\n","\n","        self.batch1 = nn.BatchNorm1d(512)\n","        self.batch2 = nn.BatchNorm1d(512)\n","\n","        self.prelu1 = nn.PReLU(512)\n","        self.prelu2 = nn.PReLU(512)\n","\n","    def forward(self, input_data):\n","        if DEBUG: \n","            print(\"ResBlock Start: shape of input_data:\", input_data.shape)\n","        x = self.conv1(input_data)\n","        x = self.prelu1(x)\n","        x = self.batch1(x)\n","        x = self.D_conv(x)\n","        if DEBUG:\n","            print(\"ResBlock middle shape:\", x.shape)\n","        #x = torch.reshape(x, (1, -1,))\n","        #x = torch.reshape(x, (-1,))\n","        if DEBUG:\n","            print(\"ResBlock po concatenaci:\", x.shape)\n","        x = self.prelu2(x)\n","        x = self.batch2(x)\n","        x = self.conv2(x)\n","        if DEBUG:\n","            print(\"ResBlock after conv2: \", x.shape)\n","            print(\"ResBlock end: input_data: \", input_data.shape)\n","        return torch.add(x, input_data)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1KMP5GHiN2MZ","colab_type":"text"},"source":["## Main NeuralNetwork Class\n"]},{"cell_type":"code","metadata":{"id":"6R_7Hpj0N2ls","colab_type":"code","colab":{}},"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv1d(1, 256, 20, bias=False, stride=nn_stride, padding=padd)\n","        #self.deconv = nn.ConvTranspose1d(256, 2, 20, padding=padd, bias=bias_enabled, stride=20)\n","        self.deconv = nn.ConvTranspose1d(512, 2, 20, padding=padd, bias=False, stride=nn_stride, groups=2)\n","\n","        self.layer_norm = nn.LayerNorm(256)\n","        self.bottleneck1 = nn.Conv1d(256, 256, 1) #TODO padding, stride???\n","        self.bottleneck2 = nn.Conv1d(256, 512, 1) #TODO 512 = NxC\n","        self.softmax = nn.Softmax(2)\n","\n","        self.resblock1 = ResBlock(256, 1)\n","        self.resblock2 = ResBlock(256, 2)\n","        self.resblock3 = ResBlock(256, 4)\n","        self.resblock4 = ResBlock(256, 8)\n","        self.resblock5 = ResBlock(256, 16)\n","        self.resblock6 = ResBlock(256, 32)\n","        self.resblock7 = ResBlock(256, 64)\n","        self.resblock8 = ResBlock(256, 128)\n","\n","        self.resblock11 = ResBlock(256, 1)\n","        self.resblock12 = ResBlock(256, 2)\n","        self.resblock13 = ResBlock(256, 4)\n","        self.resblock14 = ResBlock(256, 8)\n","        self.resblock15 = ResBlock(256, 16)\n","        self.resblock16 = ResBlock(256, 32)\n","        self.resblock17 = ResBlock(256, 64)\n","        self.resblock18 = ResBlock(256, 128)\n","\n","        # TODO je tohle OK?\n","        torch.nn.init.xavier_uniform_(self.conv1.weight)\n","        torch.nn.init.xavier_uniform_(self.deconv.weight)\n","\n","    def forward(self, input_data):\n","        # encoder\n","        if DEBUG:\n","            print(\"Net start - create representation from input_data: \", input_data.shape)\n","        #input_data = torch.unsqueeze(input_data, 1) #TODO ??\n","        if DEBUG:\n","            print(\"Net start - create representation from input_data: \", input_data.shape)\n","        representation = self.conv1(input_data)\n","        representation = fc.relu(representation)\n","        if DEBUG:    \n","            print(\"Net: advanced representation created\", representation.shape)\n","\n","        # separation - estimate masks\n","        #representation = self.layer_norm(representation) # TODO -layer norm\n","        data = self.bottleneck1(representation)\n","\n","        data = self.resblock1(data)\n","        data = self.resblock2(data)\n","        data = self.resblock3(data)\n","        data = self.resblock4(data)\n","        data = self.resblock5(data)\n","        data = self.resblock6(data)\n","        data = self.resblock7(data)\n","        data = self.resblock8(data)\n","\n","        data = self.resblock11(data)\n","        data = self.resblock12(data)\n","        data = self.resblock13(data)\n","        data = self.resblock14(data)\n","        data = self.resblock15(data)\n","        data = self.resblock16(data)\n","        data = self.resblock17(data)\n","        data = self.resblock18(data)\n","\n","        data = self.bottleneck2(data)\n","        data = torch.reshape(data, (1, 256, 2, -1,))\n","        masks = self.softmax(data)\n","        if DEBUG:\n","            print(\"NN: Masks: \", masks.shape)\n","\n","        # multiply masks and representation\n","        masked_representation = torch.mul(representation[:,:,None,:], masks)\n","        masked_representation = torch.reshape(masked_representation, (1, 512, -1))\n","        \n","        # decoder\n","        separate_data = self.deconv(masked_representation)\n","        return separate_data"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DgOHc1upOFy-","colab_type":"text"},"source":["## Data Loader Class"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"T6n7_lS9NWeI","colab":{}},"source":["class AudioDataset(data_utils.Dataset):\n","    \"\"\"\n","    Dataset of speech mixtures for speech separation.\n","    \"\"\"\n","    def __init__(self, path, transform=None):\n","        super(AudioDataset, self).__init__()\n","        self.path = path\n","        self.mixtures_path = self.path + \"mix/\"\n","        self.sources1_path  = self.path + \"s1/\"\n","        self.sources2_path  = self.path + \"s2/\"\n","\n","        self.mixtures = []\n","        self.sources1 = []\n","        self.sources2 = []\n","\n","        # self.mixtures je vektor, kde jsou ulozeny nazvy vsech audio nahravek urcenych k uceni site.\n","        self.mixtures = [mix for mix in listdir(self.mixtures_path) if isfile(join(self.mixtures_path, mix))]\n","        self.sources1 = [s1 for s1 in listdir(self.sources1_path) if isfile(join(self.sources1_path, s1))]\n","        self.sources2 = [s2 for s2 in listdir(self.sources2_path) if isfile(join(self.sources2_path, s2))]\n","\n","        # ono by vlastne stacilo rozkopirovat unique mixture do zbylych dvou sources1 a sources2 misto tech zbylych rozdilu.\n","        # V obou totiz ma byt to same a ve stejnem poctu.\n","\n","        # REMOVE DUPLICATES\n","        if DEBUG:\n","            print(\"audiodataset mixture size: \", len(self.mixtures))\n","            print(\"audiodataset sources1 size: \", len(self.sources1))\n","            print(\"audiodataset sources1 size: \", len(self.sources2))\n","        # make list unique\n","        smixtures = set(self.mixtures)\n","        ssources1 = set(self.sources1)\n","        ssources2 = set(self.sources2)\n","\n","        ms1_duplicates = smixtures - ssources1\n","        ms2_duplicates = smixtures - ssources2\n","        self.mixtures = list((smixtures - ms1_duplicates) - ms2_duplicates)\n","\n","        s1m_duplicates = ssources1 - smixtures\n","        s2m_duplicates = ssources2 - smixtures\n","        self.sources1 = list(((ssources1 - s1m_duplicates) - s2m_duplicates) - ms2_duplicates)\n","        self.sources2 = list(((ssources2 - s2m_duplicates) - s1m_duplicates) - ms1_duplicates)\n","\n","        self.mixtures.sort()\n","        self.sources1.sort()\n","        self.sources2.sort()\n","\n","        if DEBUG:\n","            print(\"audiodataset mixture size: \", len(self.mixtures))\n","            print(\"audiodataset sources1 size: \", len(self.sources1))\n","            print(\"audiodataset sources1 size: \", len(self.sources2))\n","\n","    def __len__(self):\n","        \"\"\"\n","        Vraci celkovy pocet dat, ktere jsou zpracovavane\n","        \"\"\"\n","        return len(self.mixtures)\n","\n","    def __getitem__(self, index):\n","        \"\"\"\n","        v2: transformovane a nachystane audio, ale pouze jeden segment v podobe tensoru\n","        \"\"\"\n","        if DEBUG:\n","            print(\"getItem: index:\",index, \" path: \", self.mixtures_path + self.mixtures[index])\n","            print(\"getItem: index:\",index, \" path: \", self.sources1_path + self.sources1[index])\n","            print(\"getItem: index:\",index, \" path: \", self.sources2_path + self.sources2[index])\n","        mixture = self.getAudioSamples(self.mixtures_path + self.mixtures[index])\n","        source1 = self.getAudioSamples(self.sources1_path + self.sources1[index])\n","        source2 = self.getAudioSamples(self.sources2_path + self.sources2[index])\n","        mixture.unsqueeze_(0)\n","        source1.unsqueeze_(0)\n","        source2.unsqueeze_(0)\n","        return mixture, source1, source2\n","\n","    def getAudioSamples(self, audio_file_path):\n","        \"\"\"\n","        Precte a vrati vsechny vzorky zadaneho audio souboru\n","        \"\"\"\n","        rate, samples = wav.read(audio_file_path)\n","        return self.prepare(samples)\n","\n","    def prepare(self, samples):\n","        \"\"\"\n","        Funkce prevede vstupni vzorky na numpy array a nasledne na tensor.\n","        \"\"\"\n","        # normalisation - zero mean & jednotkova variance (unit variation)\n","        numpy = np.array(samples)\n","        #normalizace\n","        numpy = numpy / 2**15\n","        tensor = torch.as_tensor(numpy)\n","        tensor_float32 = torch.tensor(tensor, dtype=torch.float32)\n","        return tensor_float32"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1Ne4JZ_7PVZ3","colab_type":"text"},"source":["# Main - Training and using NN\n","This have to be run +-3 times to make nn run. Something with too large dataset error... "]},{"cell_type":"markdown","metadata":{"id":"b5zI3nXegLWK","colab_type":"text"},"source":["## 1. Instantiate NN"]},{"cell_type":"code","metadata":{"id":"mLD1RfLOgQEh","colab_type":"code","colab":{}},"source":["tasnet = Net()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bxOYp1IJgfh1","colab_type":"text"},"source":["## 2. Use Cuda if available\n","To enable GPU backend for your notebook, go to Edit → Notebook Settings and set Hardware accelerator to GPU.\n"]},{"cell_type":"code","metadata":{"id":"5bAVMAMWkqAT","colab_type":"code","outputId":"05de0652-7727-42c2-f45e-232d139dc986","executionInfo":{"status":"ok","timestamp":1573577853444,"user_tz":-60,"elapsed":1128,"user":{"displayName":"narutokov","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAyJj_235BHAe-AhCcabJ67rI8ms6VvOAQiExuQ=s64","userId":"09699004457365288649"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Check if cuda is available\n","if use_cuda and torch.cuda.is_available():\n","  print(\"Cuda is available!\")\n","  tasnet.cuda()\n","else:\n","  print(\"Cuda is NOT available\")"],"execution_count":69,"outputs":[{"output_type":"stream","text":["Cuda is available!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JGl20A5Egz3p","colab_type":"text"},"source":["## 3. Work With Network\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"NAqfZOBG2DT8"},"source":["### TODO\n","- [opt] Load from git\n","- [opt] save to git\n","- **plot realtime graph of training loss**"]},{"cell_type":"markdown","metadata":{"id":"ezZ6t7qa0CgF","colab_type":"text"},"source":["## Set Criterion and Optimizer"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"HLkZhYsx1_Ul","colab":{}},"source":["criterion = nn.MSELoss()\n","optimizer = optim.Adam(tasnet.parameters(), lr = learning_rate, weight_decay=opt_decay)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1GRhQ-b34PzE","colab_type":"text"},"source":["## [opt] Load NN from Checkpoint "]},{"cell_type":"markdown","metadata":{"id":"4m0cm7wg1NKr","colab_type":"text"},"source":["### [opt] Load Checkpoint for continuing training"]},{"cell_type":"code","metadata":{"id":"4rBwoxHa1VFK","colab_type":"code","outputId":"6abbb6ae-c13c-459c-901d-cd82f5b03c62","executionInfo":{"status":"ok","timestamp":1573577887227,"user_tz":-60,"elapsed":890,"user":{"displayName":"narutokov","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAyJj_235BHAe-AhCcabJ67rI8ms6VvOAQiExuQ=s64","userId":"09699004457365288649"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#replace Y,M,D,H,m,X,Y  with apropriate values\n","#checkpoint = torch.load(BASE_DATA_PATH+'tasnet_model_checkpoint_Y-M-D_H:m_eX_aY.tar')\n","#checkpoint = torch.load(BASE_DATA_PATH+'tasnet_model_checkpoint_2019-11-08_04:15_e3_a19999.tar')\n","\n","checkpoint = torch.load(BASE_DATA_PATH+'tasnet_model_checkpoint_2019-11-12_00:41_X8_R2_e2_a19999.tar')\n","\n","tasnet.load_state_dict(checkpoint['model_state_dict'])\n","optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","epoch = checkpoint['epoch']\n","loss = checkpoint['loss']\n","\n","tasnet.eval() # For inference\n","# - or - continue training:\n","#tasnet.train()"],"execution_count":72,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Net(\n","  (conv1): Conv1d(1, 256, kernel_size=(20,), stride=(20,), padding=(10,), bias=False)\n","  (deconv): ConvTranspose1d(512, 2, kernel_size=(20,), stride=(20,), padding=(10,), groups=2, bias=False)\n","  (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","  (bottleneck1): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n","  (bottleneck2): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n","  (softmax): Softmax(dim=2)\n","  (resblock1): ResBlock(\n","    (conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n","    (D_conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)\n","    (conv2): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n","    (batch1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (batch2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (prelu1): PReLU(num_parameters=512)\n","    (prelu2): PReLU(num_parameters=512)\n","  )\n","  (resblock2): ResBlock(\n","    (conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n","    (D_conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), groups=512)\n","    (conv2): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n","    (batch1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (batch2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (prelu1): PReLU(num_parameters=512)\n","    (prelu2): PReLU(num_parameters=512)\n","  )\n","  (resblock3): ResBlock(\n","    (conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n","    (D_conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), groups=512)\n","    (conv2): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n","    (batch1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (batch2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (prelu1): PReLU(num_parameters=512)\n","    (prelu2): PReLU(num_parameters=512)\n","  )\n","  (resblock4): ResBlock(\n","    (conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n","    (D_conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,), groups=512)\n","    (conv2): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n","    (batch1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (batch2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (prelu1): PReLU(num_parameters=512)\n","    (prelu2): PReLU(num_parameters=512)\n","  )\n","  (resblock5): ResBlock(\n","    (conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n","    (D_conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,), groups=512)\n","    (conv2): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n","    (batch1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (batch2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (prelu1): PReLU(num_parameters=512)\n","    (prelu2): PReLU(num_parameters=512)\n","  )\n","  (resblock6): ResBlock(\n","    (conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n","    (D_conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,), groups=512)\n","    (conv2): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n","    (batch1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (batch2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (prelu1): PReLU(num_parameters=512)\n","    (prelu2): PReLU(num_parameters=512)\n","  )\n","  (resblock7): ResBlock(\n","    (conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n","    (D_conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,), groups=512)\n","    (conv2): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n","    (batch1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (batch2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (prelu1): PReLU(num_parameters=512)\n","    (prelu2): PReLU(num_parameters=512)\n","  )\n","  (resblock8): ResBlock(\n","    (conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n","    (D_conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,), groups=512)\n","    (conv2): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n","    (batch1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (batch2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (prelu1): PReLU(num_parameters=512)\n","    (prelu2): PReLU(num_parameters=512)\n","  )\n","  (resblock11): ResBlock(\n","    (conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n","    (D_conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)\n","    (conv2): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n","    (batch1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (batch2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (prelu1): PReLU(num_parameters=512)\n","    (prelu2): PReLU(num_parameters=512)\n","  )\n","  (resblock12): ResBlock(\n","    (conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n","    (D_conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), groups=512)\n","    (conv2): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n","    (batch1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (batch2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (prelu1): PReLU(num_parameters=512)\n","    (prelu2): PReLU(num_parameters=512)\n","  )\n","  (resblock13): ResBlock(\n","    (conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n","    (D_conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), groups=512)\n","    (conv2): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n","    (batch1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (batch2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (prelu1): PReLU(num_parameters=512)\n","    (prelu2): PReLU(num_parameters=512)\n","  )\n","  (resblock14): ResBlock(\n","    (conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n","    (D_conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,), groups=512)\n","    (conv2): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n","    (batch1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (batch2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (prelu1): PReLU(num_parameters=512)\n","    (prelu2): PReLU(num_parameters=512)\n","  )\n","  (resblock15): ResBlock(\n","    (conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n","    (D_conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,), groups=512)\n","    (conv2): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n","    (batch1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (batch2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (prelu1): PReLU(num_parameters=512)\n","    (prelu2): PReLU(num_parameters=512)\n","  )\n","  (resblock16): ResBlock(\n","    (conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n","    (D_conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,), groups=512)\n","    (conv2): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n","    (batch1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (batch2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (prelu1): PReLU(num_parameters=512)\n","    (prelu2): PReLU(num_parameters=512)\n","  )\n","  (resblock17): ResBlock(\n","    (conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n","    (D_conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,), groups=512)\n","    (conv2): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n","    (batch1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (batch2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (prelu1): PReLU(num_parameters=512)\n","    (prelu2): PReLU(num_parameters=512)\n","  )\n","  (resblock18): ResBlock(\n","    (conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n","    (D_conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,), groups=512)\n","    (conv2): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n","    (batch1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (batch2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (prelu1): PReLU(num_parameters=512)\n","    (prelu2): PReLU(num_parameters=512)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":72}]},{"cell_type":"markdown","metadata":{"id":"C_79odPkzcBF","colab_type":"text"},"source":["## 3. a) Training NN"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"MyR1iWtvg8Q6","outputId":"6d2821b1-5a38-4978-c84c-f81df7bccb0a","colab":{"base_uri":"https://localhost:8080/","height":559},"executionInfo":{"status":"error","timestamp":1573576444043,"user_tz":-60,"elapsed":32661,"user":{"displayName":"narutokov","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAyJj_235BHAe-AhCcabJ67rI8ms6VvOAQiExuQ=s64","userId":"09699004457365288649"}}},"source":["learning_started_date = datetime.now().strftime('%Y-%m-%d %H:%M')\n","\n","train_data_path = BASE_DATA_PATH+\"dataset/tr/\"\n","valid_data_path = BASE_DATA_PATH+\"dataset/cv/\"\n","\n","trainset = AudioDataset(train_data_path)\n","validset = AudioDataset(valid_data_path)\n","\n","# Note: We shuffle the loading process of train_dataset to make the learning process \n","# independent of data order, but the order of test_loader \n","# remains so as to examine whether we can handle unspecified bias order of inputs.\n","trainloader = data_utils.DataLoader(trainset, batch_size = MINIBATCH_SIZE, shuffle=True)\n","validloader = data_utils.DataLoader(validset, batch_size = MINIBATCH_SIZE, shuffle=False)\n","\n","best_validation_result = 42   #initial value\n","graph_x = []\n","graph_y = []\n","\n","global_audio_cnt = 0\n","#cont_epoch = 3\n","for (epoch) in range(epochs):\n","    running_loss = 0.0\n","    \n","    #epoch = epoch + cont_epoch\n","\n","    # tady by data byly dvojice puvodni delky a te nahravky\n","    for audio_cnt, data in enumerate(trainloader, 0):\n","        global_audio_cnt += 1\n","\n","        #if global_audio_cnt > audios_in_epoch:\n","        #    print(global_audio_cnt, \" \", audios_in_epoch)\n","        #    break\n","\n","        # aby se nesekal prohlizec pri trenovani\n","        if audio_cnt % 500 == 0:\n","            print(\"\")\n","            print(datetime.now().strftime('%Y-%m-%d %H:%M:%S'), epoch, audio_cnt)\n","        else: #indikace, ze se neco deje a neseklo se trenovani.\n","            print(\".\", end=\"\")\n","\n","        input_mixture  = data[0]\n","        target_source1 = data[1]\n","        target_source2 = data[2]\n","\n","        if use_cuda and torch.cuda.is_available():\n","            input_mixture = input_mixture.cuda()\n","            target_source1 = target_source1.cuda()\n","            target_source2 = target_source2.cuda()\n","\n","        optimizer.zero_grad()\n","        separated_sources = tasnet(input_mixture)\n","\n","        #print(outputs.shape, target.shape)\n","        #if target.shape[2] != outputs.shape[2]:\n","        #    target = target.narrow(2, 0, outputs.shape[2])\n","\n","        ## zkraceni nahravek tak, aby vsechny byly stejne dlouho - pocet samplu stejny\n","        smallest = min(input_mixture.shape[2], target_source1.shape[2], target_source2.shape[2], separated_sources.shape[2])\n","        input_mixture = input_mixture.narrow(2, 0, smallest)\n","        target_source1 = target_source1.narrow(2, 0, smallest)\n","        target_source2 = target_source2.narrow(2, 0, smallest)\n","        separated_sources = separated_sources.narrow(2, 0, smallest)\n","\n","        # spojeni sources do jedne matice\n","        target_sources = torch.cat((target_source1, target_source2), 1)\n","\n","        loss = criterion(separated_sources, target_sources)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # calculate average loss\n","        running_loss += loss.item()\n","\n","        # === print loss ===\n","        if audio_cnt % print_loss_frequency == print_loss_frequency - 1:\n","            print('[%d, %5d] loss: %.5f' % (epoch, audio_cnt, running_loss/print_loss_frequency))\n","            #graph_x.append(epoch) #TODO\n","            #graph_x.append(print_loss_frequency)\n","            graph_x.append(global_audio_cnt)\n","            graph_y.append(running_loss/print_loss_frequency)\n","            \n","            # Write loss to file\n","            with open(BASE_DATA_PATH + \"loss_\"+ learning_started_date + \"_X\"+X + \"_R\" + R + \".log\", \"a\") as logloss:\n","                logloss.write(str(global_audio_cnt)+\",\"+str(running_loss/print_loss_frequency)+\"\\n\")\n","\n","            running_loss = 0.0\n","\n","        # === Create checkpoint ===\n","        if audio_cnt % create_checkpoint_frequency == create_checkpoint_frequency - 1:\n","            # Create snapshot - checkpoint\n","            torch.save({\n","              'epoch': epoch,\n","              'audio_cnt': audio_cnt,\n","              'model_state_dict': tasnet.state_dict(),\n","              'optimizer_state_dict': optimizer.state_dict(),\n","              'loss': loss,\n","            }, BASE_DATA_PATH+'tasnet_model_checkpoint_'+str(datetime.now().strftime('%Y-%m-%d_%H:%M'))+'_X'+str(X)+'_R'+str(R)+'_e'+str(epoch)+'_a'+str(audio_cnt)+'.tar')\n","\n","        # === Save audio ===\n","        # ulozeni pouze prvni nahravky pro porovnani epoch\n","        #if audio_cnt == 0:\n","        # ulozit kazdou Xtou rekonstrukci pro moznost jejiho prehrati a zjisteni, jak to zni.\n","        if audio_cnt % audio_save_frequency == 0:\n","            mixture_prep = 0\n","            source1_prep = 0\n","            source2_prep = 0\n","\n","            if use_cuda and torch.cuda.is_available():\n","                mixture_prep = input_mixture.cpu().detach().numpy()\n","                source1_prep = separated_sources[0][0].cpu().detach().numpy()\n","                source2_prep = separated_sources[0][1].cpu().detach().numpy()\n","            else:\n","                mixture_prep = input_mixture.detach().numpy()\n","                source1_prep = separated_sources[0][0].detach().numpy()\n","                source2_prep = separated_sources[0][1].detach().numpy()\n","\n","            wav.write(BASE_DATA_PATH+\"reconstruction/speech_e\"+str(epoch)+\"_a\"+str(audio_cnt)+\"_s1.wav\", 8000, source1_prep)\n","            wav.write(BASE_DATA_PATH+\"reconstruction/speech_e\"+str(epoch)+\"_a\"+str(audio_cnt)+\"_s2.wav\", 8000, source2_prep)\n","            wav.write(BASE_DATA_PATH+\"reconstruction/speech_e\"+str(epoch)+\"_a\"+str(audio_cnt)+\"_mix.wav\", 8000, mixture_prep)\n","    # ==== End Of Epoch of training ====\n","\n","    # === validation na konci epochy ===\n","    print(\"\")\n","    print(\"Validace\")\n","    valid_audio_cnt = 0\n","    running_loss = 0.0\n","    current_validation_result = 0\n","\n","    for audio_cnt, data in enumerate(validloader, 0):\n","        #if valid_audio_cnt >= 2000:\n","        #    print(\"Zpracovano \", valid_audio_cnt, \"validacnich nahravek. Konec validace.\")\n","        #    break #TODO pak oddelat\n","        valid_audio_cnt += 1\n","\n","        input_mixture  = data[0]\n","        target_source1 = data[1]\n","        target_source2 = data[2]\n","\n","        if use_cuda and torch.cuda.is_available():\n","            input_mixture = input_mixture.cuda()\n","            target_source1 = target_source1.cuda()\n","            target_source2 = target_source2.cuda()\n","\n","        #optimizer.zero_grad()\n","        separated_sources = tasnet(input_mixture)\n","\n","        smallest = min(input_mixture.shape[2], target_source1.shape[2], target_source2.shape[2], separated_sources.shape[2])\n","        input_mixture = input_mixture.narrow(2, 0, smallest)\n","        target_source1 = target_source1.narrow(2, 0, smallest)\n","        target_source2 = target_source2.narrow(2, 0, smallest)\n","        separated_sources = separated_sources.narrow(2, 0, smallest)\n","\n","        # spojeni sources do jedne matice\n","        target_sources = torch.cat((target_source1, target_source2), 1)\n","\n","        loss = criterion(separated_sources, target_sources)\n","\n","        current_validation_result += loss.item()\n","        running_loss += loss.item()\n","        if audio_cnt % print_valid_loss_frequency == print_valid_loss_frequency-1:\n","            print('[%5d] loss: %.4f' % (audio_cnt + 1, running_loss/print_valid_loss_frequency))\n","            running_loss = 0.0\n","\n","    # vyhodnoceni validace\n","    # TODO vykreslit i tuto loss, ukladat a upravit funkci aby vykreslila obe dve z trenovani i validacni a jinou barvou rpes sebe. (GIT)\n","    current_validation_result /= valid_audio_cnt # prumer\n","    print(current_validation_result, \" \", best_validation_result)\n","    if current_validation_result >= best_validation_result:\n","        learning_rate /= 2 #TODO zjistit kdy se to ma delit\n","    else:\n","        best_validation_result = current_validation_result\n","    print('Finished Validating')\n","    print('')\n","\n","\n","# Save Network For Inference in the end of training\n","torch.save(tasnet.state_dict(), BASE_DATA_PATH+'tasnet_model_inference'+'_X'+str(X)+'_R'+str(R)+'_e'+str(epoch)+'_ga'+str(global_audio_cnt)+'.pkl')\n","print('Finished Training')\n","\n","plt.plot(graph_x, graph_y)\n","plt.show()\n"],"execution_count":57,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"],"name":"stderr"},{"output_type":"stream","text":["\n","2019-11-12 16:33:05 0 0\n","torch.Size([1, 1, 41150])\n",".torch.Size([1, 1, 77037])\n",".torch.Size([1, 1, 49682])\n",".torch.Size([1, 1, 39143])\n",".torch.Size([1, 1, 39200])\n",".torch.Size([1, 1, 42715])\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-57-40044a090c0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# tady by data byly dvojice puvodni delky a te nahravky\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0maudio_cnt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mglobal_audio_cnt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-d0ff2d98a1ba>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"getItem: index:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" path: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msources2_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msources2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mmixture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetAudioSamples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixtures_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixtures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0msource1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetAudioSamples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msources1_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msources1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0msource2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetAudioSamples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msources2_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msources2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mmixture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-d0ff2d98a1ba>\u001b[0m in \u001b[0;36mgetAudioSamples\u001b[0;34m(self, audio_file_path)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mPrecte\u001b[0m \u001b[0ma\u001b[0m \u001b[0mvrati\u001b[0m \u001b[0mvsechny\u001b[0m \u001b[0mvzorky\u001b[0m \u001b[0mzadaneho\u001b[0m \u001b[0maudio\u001b[0m \u001b[0msouboru\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \"\"\"\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwav\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/io/wavfile.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(filename, mmap)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0mfile_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_big_endian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_riff_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m         \u001b[0mfmt_chunk_received\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0mchannels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/io/wavfile.py\u001b[0m in \u001b[0;36m_read_riff_chunk\u001b[0;34m(fid)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_read_riff_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0mstr1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# File signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstr1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb'RIFF'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mis_big_endian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"S8zzAG302t47","colab_type":"text"},"source":["## b) Test Network\n","- used for calculating SI-SNR, experiments"]},{"cell_type":"markdown","metadata":{"id":"b_hDJqwzxU5z","colab_type":"text"},"source":["### [opt] Load network for Inference (Production)\n","https://pytorch.org/tutorials/beginner/saving_loading_models.html"]},{"cell_type":"code","metadata":{"id":"GKHwMr3uxYKX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"f0a5954f-d99e-434f-db40-9726b578535f","executionInfo":{"status":"ok","timestamp":1573576960357,"user_tz":-60,"elapsed":880,"user":{"displayName":"narutokov","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAyJj_235BHAe-AhCcabJ67rI8ms6VvOAQiExuQ=s64","userId":"09699004457365288649"}}},"source":["tasnet.load_state_dict(torch.load(BASE_DATA_PATH+'tasnet_model_inference_X8_R2_e2_ga60000.pkl'))\n","tasnet.eval()"],"execution_count":63,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Net(\n","  (conv1): Conv1d(1, 256, kernel_size=(20,), stride=(20,), padding=(10,), bias=False)\n","  (deconv): ConvTranspose1d(512, 2, kernel_size=(20,), stride=(20,), padding=(10,), groups=2, bias=False)\n","  (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","  (bottleneck1): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n","  (bottleneck2): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n","  (softmax): Softmax(dim=2)\n","  (resblock1): ResBlock(\n","    (conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n","    (D_conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)\n","    (conv2): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n","    (batch1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (batch2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (prelu1): PReLU(num_parameters=512)\n","    (prelu2): PReLU(num_parameters=512)\n","  )\n","  (resblock2): ResBlock(\n","    (conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n","    (D_conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), groups=512)\n","    (conv2): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n","    (batch1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (batch2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (prelu1): PReLU(num_parameters=512)\n","    (prelu2): PReLU(num_parameters=512)\n","  )\n","  (resblock3): ResBlock(\n","    (conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n","    (D_conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), groups=512)\n","    (conv2): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n","    (batch1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (batch2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (prelu1): PReLU(num_parameters=512)\n","    (prelu2): PReLU(num_parameters=512)\n","  )\n","  (resblock4): ResBlock(\n","    (conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n","    (D_conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,), groups=512)\n","    (conv2): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n","    (batch1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (batch2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (prelu1): PReLU(num_parameters=512)\n","    (prelu2): PReLU(num_parameters=512)\n","  )\n","  (resblock5): ResBlock(\n","    (conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n","    (D_conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,), groups=512)\n","    (conv2): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n","    (batch1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (batch2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (prelu1): PReLU(num_parameters=512)\n","    (prelu2): PReLU(num_parameters=512)\n","  )\n","  (resblock6): ResBlock(\n","    (conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n","    (D_conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,), groups=512)\n","    (conv2): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n","    (batch1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (batch2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (prelu1): PReLU(num_parameters=512)\n","    (prelu2): PReLU(num_parameters=512)\n","  )\n","  (resblock7): ResBlock(\n","    (conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n","    (D_conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,), groups=512)\n","    (conv2): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n","    (batch1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (batch2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (prelu1): PReLU(num_parameters=512)\n","    (prelu2): PReLU(num_parameters=512)\n","  )\n","  (resblock8): ResBlock(\n","    (conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n","    (D_conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,), groups=512)\n","    (conv2): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n","    (batch1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (batch2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (prelu1): PReLU(num_parameters=512)\n","    (prelu2): PReLU(num_parameters=512)\n","  )\n","  (resblock11): ResBlock(\n","    (conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n","    (D_conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)\n","    (conv2): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n","    (batch1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (batch2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (prelu1): PReLU(num_parameters=512)\n","    (prelu2): PReLU(num_parameters=512)\n","  )\n","  (resblock12): ResBlock(\n","    (conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n","    (D_conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), groups=512)\n","    (conv2): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n","    (batch1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (batch2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (prelu1): PReLU(num_parameters=512)\n","    (prelu2): PReLU(num_parameters=512)\n","  )\n","  (resblock13): ResBlock(\n","    (conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n","    (D_conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), groups=512)\n","    (conv2): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n","    (batch1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (batch2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (prelu1): PReLU(num_parameters=512)\n","    (prelu2): PReLU(num_parameters=512)\n","  )\n","  (resblock14): ResBlock(\n","    (conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n","    (D_conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,), groups=512)\n","    (conv2): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n","    (batch1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (batch2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (prelu1): PReLU(num_parameters=512)\n","    (prelu2): PReLU(num_parameters=512)\n","  )\n","  (resblock15): ResBlock(\n","    (conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n","    (D_conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,), groups=512)\n","    (conv2): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n","    (batch1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (batch2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (prelu1): PReLU(num_parameters=512)\n","    (prelu2): PReLU(num_parameters=512)\n","  )\n","  (resblock16): ResBlock(\n","    (conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n","    (D_conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,), groups=512)\n","    (conv2): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n","    (batch1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (batch2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (prelu1): PReLU(num_parameters=512)\n","    (prelu2): PReLU(num_parameters=512)\n","  )\n","  (resblock17): ResBlock(\n","    (conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n","    (D_conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,), groups=512)\n","    (conv2): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n","    (batch1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (batch2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (prelu1): PReLU(num_parameters=512)\n","    (prelu2): PReLU(num_parameters=512)\n","  )\n","  (resblock18): ResBlock(\n","    (conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n","    (D_conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,), groups=512)\n","    (conv2): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n","    (batch1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (batch2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (prelu1): PReLU(num_parameters=512)\n","    (prelu2): PReLU(num_parameters=512)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":63}]},{"cell_type":"markdown","metadata":{"id":"TuSCsf-qZjtu","colab_type":"text"},"source":["### Run testing "]},{"cell_type":"code","metadata":{"id":"KXDQAxJz2wcn","colab_type":"code","colab":{}},"source":["# Load Test dataset\n","test_data_path = BASE_DATA_PATH+\"dataset/tt/\"\n","testset        = AudioDataset(test_data_path)\n","testloader     = data_utils.DataLoader(testset, batch_size = MINIBATCH_SIZE, shuffle=False)\n","\n","# Start Testing\n","global_audio_cnt = 0\n","# pridat zde do testovani SI_SNR  a pro kazdou nahravku a vysledky zprumerovat a vyhodnotit (GIT)\n","for audio_cnt, data in enumerate(testloader, 0):\n","    global_audio_cnt += 1\n","    \n","    input_mixture  = data[0]\n","    target_source1 = data[1]\n","    target_source2 = data[2]\n","\n","    if use_cuda and torch.cuda.is_available():\n","        input_mixture = input_mixture.cuda()\n","        target_source1 = target_source1.cuda()\n","        target_source2 = target_source2.cuda()\n","\n","    #optimizer.zero_grad()\n","    separated_sources = tasnet(input_mixture)\n","\n","    smallest = min(input_mixture.shape[2], target_source1.shape[2], target_source2.shape[2], separated_sources.shape[2])\n","    input_mixture = input_mixture.narrow(2, 0, smallest)\n","    target_source1 = target_source1.narrow(2, 0, smallest)\n","    target_source2 = target_source2.narrow(2, 0, smallest)\n","    separated_sources = separated_sources.narrow(2, 0, smallest)\n","\n","    # spojeni sources do jedne matice\n","    target_sources = torch.cat((target_source1, target_source2), 1)\n","\n","    loss = criterion(separated_sources, target_sources)\n","\n","    running_loss += loss.item()\n","    if audio_cnt % print_loss_frequency == print_loss_frequency-1:\n","        print('[%5d] loss: %.4f' % (audio_cnt+1, running_loss/print_loss_frequency))\n","        running_loss = 0.0\n","    \n","    # === Save audio ===\n","    if audio_cnt % audio_save_frequency == 0:\n","        mixture_prep = 0\n","        source1_prep = 0\n","        source2_prep = 0\n","\n","        if use_cuda and torch.cuda.is_available():\n","            mixture_prep = input_mixture.cpu().detach().numpy()\n","            source1_prep = separated_sources[0][0].cpu().detach().numpy()\n","            source2_prep = separated_sources[0][1].cpu().detach().numpy()\n","        else:\n","            mixture_prep = input_mixture.detach().numpy()\n","            source1_prep = separated_sources[0][0].detach().numpy()\n","            source2_prep = separated_sources[0][1].detach().numpy()\n","\n","        wav.write(BASE_DATA_PATH+\"testdata_recon/speech_e\"+str(epoch)+\"_a\"+str(audio_cnt)+\"_s1.wav\", 8000, source1_prep)\n","        wav.write(BASE_DATA_PATH+\"testdata_recon/speech_e\"+str(epoch)+\"_a\"+str(audio_cnt)+\"_s2.wav\", 8000, source2_prep)\n","        wav.write(BASE_DATA_PATH+\"testdata_recon/speech_e\"+str(epoch)+\"_a\"+str(audio_cnt)+\"_mix.wav\", 8000, mixture_prep)\n","\n","print('Finished Testing')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"umSfQ7OH24rB","colab_type":"text"},"source":["## c) Network Inference\n"]},{"cell_type":"code","metadata":{"id":"oCS1IYM729N9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":124},"outputId":"52a3d65d-0a47-4e10-e27c-9f7c78be5556","executionInfo":{"status":"ok","timestamp":1573577898819,"user_tz":-60,"elapsed":1010,"user":{"displayName":"narutokov","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAyJj_235BHAe-AhCcabJ67rI8ms6VvOAQiExuQ=s64","userId":"09699004457365288649"}}},"source":["print('Prepared for inference, load your audio.')\n","\n","# TODO Rozdlit do souboru a parametrizovat (GIT)\n","\n","# set audio name for inferencion\n","mix_name = \"mix2.wav\"\n","\n","# ================================================================\n","def prepare(samples):\n","    \"\"\"\n","    Funkce prevede vstupni vzorky na numpy array a nasledne na tensor.\n","    \"\"\"\n","    # normalisation - zero mean & jednotkova variance (unit variation)\n","    numpy = np.array(samples)\n","    #normalizace\n","    numpy = numpy / 2**15\n","    tensor = torch.as_tensor(numpy)\n","    tensor_float32 = torch.tensor(tensor, dtype=torch.float32)\n","    return tensor_float32\n","\n","def getAudioSamples(audio_file_path):\n","    rate, samples = wav.read(audio_file_path)\n","    return prepare(samples)\n","# ================================================================\n","\n","data_path = BASE_DATA_PATH + \"inferencedata/\" + mix_name\n","\n","#data_path = BASE_DATA_PATH + \"inferencedata/\"# + mix_name\n","#mixtures = []\n","#mixtures = [mix for mix in listdir(data_path) if isfile(join(data_path, mix))]\n","#mixture = getAudioSamples(data_path + mixtures[index])\n","\n","mixture = getAudioSamples(data_path)\n","mixture.unsqueeze_(0)\n","mixture.unsqueeze_(0)\n","\n","input_mixture = mixture\n","\n","if use_cuda and torch.cuda.is_available():\n","    input_mixture = input_mixture.cuda()\n","\n","separated_sources = tasnet(input_mixture)\n","\n","# === Save audio ===\n","mixture_prep = 0\n","source1_prep = 0\n","source2_prep = 0\n","\n","if use_cuda and torch.cuda.is_available():\n","    mixture_prep = input_mixture.cpu().detach().numpy()\n","    source1_prep = separated_sources[0][0].cpu().detach().numpy()\n","    source2_prep = separated_sources[0][1].cpu().detach().numpy()\n","else:\n","    mixture_prep = input_mixture.detach().numpy()\n","    source1_prep = separated_sources[0][0].detach().numpy()\n","    source2_prep = separated_sources[0][1].detach().numpy()\n","\n","wav.write(BASE_DATA_PATH+\"inferenced/\" + \"s1-\" + mix_name, 8000, source1_prep)\n","wav.write(BASE_DATA_PATH+\"inferenced/\" + \"s2-\" + mix_name, 8000, source2_prep)\n","\n","print(\"Inference done, separated speakers saved into \" + BASE_DATA_PATH + \"inferenced/\")\n"],"execution_count":73,"outputs":[{"output_type":"stream","text":["Prepared for inference, load your audio.\n","torch.Size([1, 1, 74880])\n","Inference done, separated speakers saved into /gdrive/My Drive/FIT/inferenced/\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  app.launch_new_instance()\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"yh0XKV8_KUD_","colab_type":"text"},"source":["# Plot loss graph "]},{"cell_type":"code","metadata":{"id":"UwWKtLabKWe8","colab_type":"code","outputId":"8afabd2d-5dc6-4774-b456-cf096e79adda","executionInfo":{"status":"ok","timestamp":1573578544672,"user_tz":-60,"elapsed":3003,"user":{"displayName":"narutokov","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAyJj_235BHAe-AhCcabJ67rI8ms6VvOAQiExuQ=s64","userId":"09699004457365288649"}},"colab":{"base_uri":"https://localhost:8080/","height":310}},"source":["import matplotlib.pyplot as plt\n","import csv\n","\n","x = []\n","y = []\n","\n","learning_started_date=\"2019-11-12 01:01\"\n","\n","losspath = BASE_DATA_PATH + \"loss_\"+ learning_started_date + \".log\"\n","with open(losspath,'r') as csvfile:\n","    plots = csv.reader(csvfile, delimiter=',')\n","    for row in plots:\n","        x.append(float(row[0]))\n","        y.append(float(row[1]))\n","\n","plt.plot(x,y, label='Loaded from file!')\n","plt.xlabel('number of processed audio')\n","plt.ylabel('loss')\n","plt.title('Interesting Graph\\nCheck it out')\n","plt.legend()\n","plt.show()"],"execution_count":74,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAZgAAAElCAYAAADZb/T+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]}]}